{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial: Pitch & Frequency Analysis with librosa\n",
        "\n",
        "This tutorial explores how to analyze pitch and frequency content in audio. Understanding harmonic content is fundamental to computational musicology, automatic transcription, and instrument recognition.\n",
        "\n",
        "**What you'll learn:**\n",
        "- How to visualize frequency spectra\n",
        "- How to create chromagrams for harmonic analysis\n",
        "- How to detect pitch using the PYIN algorithm\n",
        "- How to separate harmonic and percussive components"
      ],
      "metadata": {
        "id": "intro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Setup\n",
        "\n",
        "Install and import the required libraries."
      ],
      "metadata": {
        "id": "setup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install libraries\n",
        "!pip install librosa soundfile\n",
        "\n",
        "# Import libraries\n",
        "import librosa\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Audio\n",
        "from collections import Counter\n",
        "\n",
        "print(\"Libraries loaded successfully!\")"
      ],
      "metadata": {
        "id": "setup_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Load Audio and View Spectrum\n",
        "\n",
        "The frequency spectrum shows the intensity of each frequency at a single moment—like a snapshot of harmonic content."
      ],
      "metadata": {
        "id": "spectrum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load audio\n",
        "y, sr = librosa.load(librosa.ex('trumpet'))\n",
        "\n",
        "# Listen to the audio\n",
        "print(\"Listen to the audio:\")\n",
        "Audio(y, rate=sr)"
      ],
      "metadata": {
        "id": "load_audio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the Short-Time Fourier Transform\n",
        "D = librosa.stft(y)\n",
        "\n",
        "# Take the magnitude of one frame (middle of the audio)\n",
        "frame_idx = len(D[0]) // 2\n",
        "spectrum = np.abs(D[:, frame_idx])\n",
        "\n",
        "# Create frequency axis\n",
        "frequencies = librosa.fft_frequencies(sr=sr)\n",
        "\n",
        "# Plot the spectrum\n",
        "plt.figure(figsize=(14, 4))\n",
        "plt.plot(frequencies, spectrum)\n",
        "plt.xlabel('Frequency (Hz)')\n",
        "plt.ylabel('Magnitude')\n",
        "plt.title('Frequency Spectrum (Single Frame)')\n",
        "plt.xlim(0, 5000)  # Focus on 0-5000 Hz\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "spectrum_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reading a spectrum:**\n",
        "- First peak (leftmost) = Fundamental frequency\n",
        "- Higher peaks = Harmonics (integer multiples of fundamental)\n",
        "- Pattern of peak heights = Instrument timbre"
      ],
      "metadata": {
        "id": "spectrum_explain"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Create a Chromagram\n",
        "\n",
        "A **chromagram** shows energy in each of the 12 pitch classes (C, C#, D, etc.) over time. It collapses all octaves together—useful for chord detection and key analysis."
      ],
      "metadata": {
        "id": "chromagram"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the chromagram\n",
        "chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(14, 4))\n",
        "librosa.display.specshow(chroma, y_axis='chroma', x_axis='time', cmap='coolwarm')\n",
        "plt.colorbar(label='Intensity')\n",
        "plt.title('Chromagram - Pitch Class Energy Over Time')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "chromagram_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reading a chromagram:**\n",
        "- Bright horizontal bands = Strong pitch class presence\n",
        "- Vertical patterns = Chord changes\n",
        "- Constant brightness in one row = Sustained note or pedal tone"
      ],
      "metadata": {
        "id": "chromagram_explain"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Pitch Detection with PYIN\n",
        "\n",
        "**PYIN** (Probabilistic YIN) detects the fundamental frequency of a monophonic signal—perfect for melody analysis."
      ],
      "metadata": {
        "id": "pyin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Detect pitch using PYIN\n",
        "f0, voiced_flag, voiced_probs = librosa.pyin(\n",
        "    y, \n",
        "    fmin=librosa.note_to_hz('C2'),\n",
        "    fmax=librosa.note_to_hz('C7')\n",
        ")\n",
        "\n",
        "# Create time axis\n",
        "times = librosa.times_like(f0)\n",
        "\n",
        "# Plot the detected pitch\n",
        "plt.figure(figsize=(14, 4))\n",
        "plt.plot(times, f0, label='Detected F0', color='blue')\n",
        "plt.xlabel('Time (seconds)')\n",
        "plt.ylabel('Frequency (Hz)')\n",
        "plt.title('Pitch Detection using PYIN')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print statistics\n",
        "valid_f0 = f0[~np.isnan(f0)]\n",
        "if len(valid_f0) > 0:\n",
        "    print(f\"Average detected pitch: {np.mean(valid_f0):.1f} Hz\")\n",
        "    print(f\"Pitch range: {np.min(valid_f0):.1f} - {np.max(valid_f0):.1f} Hz\")"
      ],
      "metadata": {
        "id": "pyin_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Convert Frequencies to Note Names\n",
        "\n",
        "Make pitch analysis more musical by converting frequencies to note names."
      ],
      "metadata": {
        "id": "note_names"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert detected pitches to note names\n",
        "def hz_to_note_name(freq):\n",
        "    \"\"\"Convert frequency to note name, handling NaN values.\"\"\"\n",
        "    if np.isnan(freq):\n",
        "        return None\n",
        "    return librosa.hz_to_note(freq)\n",
        "\n",
        "# Get unique notes detected\n",
        "valid_pitches = f0[~np.isnan(f0)]\n",
        "note_names = [hz_to_note_name(freq) for freq in valid_pitches]\n",
        "\n",
        "# Count occurrences of each note\n",
        "note_counts = Counter(note_names)\n",
        "\n",
        "print(\"Most common notes detected:\")\n",
        "for note, count in note_counts.most_common(10):\n",
        "    print(f\"  {note}: {count} frames\")"
      ],
      "metadata": {
        "id": "note_names_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Overlay Pitch on Spectrogram\n",
        "\n",
        "Visualizing detected pitch on a spectrogram helps verify accuracy—the pitch line should follow the brightest harmonic contours."
      ],
      "metadata": {
        "id": "overlay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create figure\n",
        "fig, ax = plt.subplots(figsize=(14, 6))\n",
        "\n",
        "# Plot spectrogram\n",
        "D_db = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
        "img = librosa.display.specshow(D_db, sr=sr, x_axis='time', y_axis='hz', ax=ax, cmap='magma')\n",
        "\n",
        "# Overlay detected pitch\n",
        "times = librosa.times_like(f0)\n",
        "ax.plot(times, f0, color='cyan', linewidth=2, label='Detected Pitch')\n",
        "\n",
        "ax.set_ylim(0, 2000)  # Focus on lower frequencies\n",
        "ax.legend(loc='upper right')\n",
        "ax.set_title('Spectrogram with Detected Pitch Overlay')\n",
        "plt.colorbar(img, ax=ax, format='%+2.0f dB')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "overlay_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Harmonic-Percussive Source Separation\n",
        "\n",
        "librosa can separate **harmonic** (pitched) and **percussive** (rhythmic) components. This is useful for isolating melody or drums."
      ],
      "metadata": {
        "id": "hpss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate harmonic and percussive components\n",
        "y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
        "\n",
        "# Create visualizations\n",
        "fig, axes = plt.subplots(3, 1, figsize=(14, 10))\n",
        "\n",
        "# Original\n",
        "librosa.display.waveshow(y, sr=sr, ax=axes[0], alpha=0.7)\n",
        "axes[0].set_title('Original Audio')\n",
        "\n",
        "# Harmonic\n",
        "librosa.display.waveshow(y_harmonic, sr=sr, ax=axes[1], alpha=0.7, color='blue')\n",
        "axes[1].set_title('Harmonic Component (Pitched sounds)')\n",
        "\n",
        "# Percussive\n",
        "librosa.display.waveshow(y_percussive, sr=sr, ax=axes[2], alpha=0.7, color='red')\n",
        "axes[2].set_title('Percussive Component (Transients, drums)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hpss_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Listen to the original\n",
        "print(\"Original:\")\n",
        "Audio(y, rate=sr)"
      ],
      "metadata": {
        "id": "hpss_original"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Listen to harmonic component\n",
        "print(\"Harmonic component only (pitched sounds):\")\n",
        "Audio(y_harmonic, rate=sr)"
      ],
      "metadata": {
        "id": "hpss_harmonic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Listen to percussive component\n",
        "print(\"Percussive component only (transients):\")\n",
        "Audio(y_percussive, rate=sr)"
      ],
      "metadata": {
        "id": "hpss_percussive"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 8: Key Detection via Pitch Class Distribution\n",
        "\n",
        "Analyzing which pitch classes are most prominent can hint at the musical key."
      ],
      "metadata": {
        "id": "key_detection"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute chromagram (using CQT for better low-frequency resolution)\n",
        "chroma = librosa.feature.chroma_cqt(y=y, sr=sr)\n",
        "\n",
        "# Sum across time to get overall pitch class distribution\n",
        "chroma_sum = np.sum(chroma, axis=1)\n",
        "\n",
        "# Normalize\n",
        "chroma_sum = chroma_sum / np.max(chroma_sum)\n",
        "\n",
        "# Pitch class names\n",
        "pitch_classes = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
        "\n",
        "# Plot pitch class distribution\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.bar(pitch_classes, chroma_sum, color='steelblue')\n",
        "plt.xlabel('Pitch Class')\n",
        "plt.ylabel('Normalized Energy')\n",
        "plt.title('Pitch Class Distribution')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Find the most prominent pitch class\n",
        "dominant_pc = pitch_classes[np.argmax(chroma_sum)]\n",
        "print(f\"Most prominent pitch class: {dominant_pc}\")\n",
        "print(\"(This suggests the piece may be in or related to this key)\")"
      ],
      "metadata": {
        "id": "key_detection_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 9: Complete Pitch Analysis Function\n",
        "\n",
        "A reusable function for comprehensive pitch analysis."
      ],
      "metadata": {
        "id": "complete"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_pitch(y, sr):\n",
        "    \"\"\"Comprehensive pitch analysis function.\"\"\"\n",
        "    \n",
        "    results = {}\n",
        "    \n",
        "    # 1. Detect pitch with PYIN\n",
        "    f0, voiced_flag, voiced_probs = librosa.pyin(\n",
        "        y, \n",
        "        fmin=librosa.note_to_hz('C2'),\n",
        "        fmax=librosa.note_to_hz('C7')\n",
        "    )\n",
        "    \n",
        "    valid_f0 = f0[~np.isnan(f0)]\n",
        "    \n",
        "    if len(valid_f0) > 0:\n",
        "        results['avg_pitch_hz'] = float(np.mean(valid_f0))\n",
        "        results['min_pitch_hz'] = float(np.min(valid_f0))\n",
        "        results['max_pitch_hz'] = float(np.max(valid_f0))\n",
        "        results['avg_note'] = librosa.hz_to_note(results['avg_pitch_hz'])\n",
        "    else:\n",
        "        results['avg_pitch_hz'] = None\n",
        "        results['avg_note'] = None\n",
        "    \n",
        "    # 2. Compute chromagram and find dominant pitch class\n",
        "    chroma = librosa.feature.chroma_cqt(y=y, sr=sr)\n",
        "    chroma_sum = np.sum(chroma, axis=1)\n",
        "    pitch_classes = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
        "    results['dominant_pitch_class'] = pitch_classes[np.argmax(chroma_sum)]\n",
        "    \n",
        "    # 3. Harmonic-Percussive ratio\n",
        "    y_harm, y_perc = librosa.effects.hpss(y)\n",
        "    harm_energy = np.sum(y_harm**2)\n",
        "    perc_energy = np.sum(y_perc**2)\n",
        "    results['harmonic_ratio'] = float(harm_energy / (harm_energy + perc_energy + 1e-10))\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Run analysis\n",
        "results = analyze_pitch(y, sr)\n",
        "\n",
        "print(\"=== Pitch Analysis Results ===\")\n",
        "for key, value in results.items():\n",
        "    if isinstance(value, float):\n",
        "        print(f\"{key}: {value:.2f}\")\n",
        "    else:\n",
        "        print(f\"{key}: {value}\")"
      ],
      "metadata": {
        "id": "complete_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 10: Upload Your Own Audio\n",
        "\n",
        "Try the analysis on your own audio file!"
      ],
      "metadata": {
        "id": "upload"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload your own file\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "if uploaded:\n",
        "    filename = list(uploaded.keys())[0]\n",
        "    y_custom, sr_custom = librosa.load(filename)\n",
        "    \n",
        "    print(f\"\\nLoaded: {filename}\")\n",
        "    print(f\"Duration: {len(y_custom) / sr_custom:.2f} seconds\")\n",
        "    \n",
        "    # Analyze\n",
        "    results_custom = analyze_pitch(y_custom, sr_custom)\n",
        "    \n",
        "    print(\"\\n=== Analysis Results ===\")\n",
        "    for key, value in results_custom.items():\n",
        "        if isinstance(value, float):\n",
        "            print(f\"{key}: {value:.2f}\")\n",
        "        else:\n",
        "            print(f\"{key}: {value}\")\n",
        "    \n",
        "    # Listen\n",
        "    Audio(y_custom, rate=sr_custom)"
      ],
      "metadata": {
        "id": "upload_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Practice Exercises\n",
        "\n",
        "1. **Compare instruments**: Load trumpet, piano, and guitar recordings and compare their harmonic ratios\n",
        "2. **Melody extraction**: Use HPSS to isolate harmonic content, then run PYIN on that\n",
        "3. **Transpose detection**: Compare chromagrams of two versions of the same song in different keys"
      ],
      "metadata": {
        "id": "exercises"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Practice space - try the exercises here!\n",
        "\n",
        "# Exercise 2: Improved pitch detection on harmonic-only audio\n",
        "# y_harm, _ = librosa.effects.hpss(y)\n",
        "# f0_harm, _, _ = librosa.pyin(y_harm, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7'))\n",
        "# # Compare with original f0..."
      ],
      "metadata": {
        "id": "practice"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Key Concepts Summary\n",
        "\n",
        "1. **Frequency spectrum** shows harmonic content at one moment\n",
        "2. **Chromagrams** show pitch class energy over time (octave-independent)\n",
        "3. **PYIN** detects fundamental frequency in monophonic audio\n",
        "4. **Harmonic-Percussive separation** isolates pitched and rhythmic elements\n",
        "5. **Pitch class distribution** can hint at musical key\n",
        "\n",
        "---\n",
        "\n",
        "**Next tutorial**: Learn about audio effects and exporting with soundfile!"
      ],
      "metadata": {
        "id": "summary"
      }
    }
  ]
}
