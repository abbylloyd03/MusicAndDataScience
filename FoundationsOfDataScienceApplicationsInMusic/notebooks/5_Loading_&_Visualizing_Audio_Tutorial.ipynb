{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial: Loading & Visualizing Audio with librosa\n",
        "\n",
        "This tutorial introduces you to **librosa**, a powerful Python library for audio analysis. You'll learn how to load audio files and create visualizations that reveal the structure of sound—skills fundamental to computational music analysis.\n",
        "\n",
        "**What you'll learn:**\n",
        "- How to load audio files into Python\n",
        "- How to visualize audio as waveforms\n",
        "- How to create spectrograms that show frequency content over time\n",
        "- How to use Mel spectrograms for perceptually-meaningful analysis"
      ],
      "metadata": {
        "id": "intro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Setup\n",
        "\n",
        "First, let's install and import the libraries we need. This may take a minute to run."
      ],
      "metadata": {
        "id": "setup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install librosa soundfile\n",
        "\n",
        "# Import libraries\n",
        "import librosa\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Audio\n",
        "\n",
        "print(\"Libraries loaded successfully!\")"
      ],
      "metadata": {
        "id": "setup_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Load an Audio File\n",
        "\n",
        "librosa makes loading audio simple. The `librosa.load()` function returns two things:\n",
        "- **y**: The audio signal as a NumPy array (a sequence of numbers representing the waveform)\n",
        "- **sr**: The sample rate (how many samples per second)\n",
        "\n",
        "We'll use one of librosa's built-in example files—a trumpet sound."
      ],
      "metadata": {
        "id": "load_audio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a built-in example (trumpet sound)\n",
        "y, sr = librosa.load(librosa.ex('trumpet'))\n",
        "\n",
        "# Print basic information about the audio\n",
        "print(f\"Sample rate: {sr} Hz\")\n",
        "print(f\"Duration: {len(y) / sr:.2f} seconds\")\n",
        "print(f\"Number of samples: {len(y)}\")\n",
        "\n",
        "# Listen to the audio\n",
        "Audio(y, rate=sr)"
      ],
      "metadata": {
        "id": "load_audio_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Understanding Sample Rate\n",
        "\n",
        "The sample rate tells us how many \"snapshots\" of the sound wave were taken per second. CD quality audio uses 44,100 samples per second (44.1 kHz). librosa defaults to 22,050 Hz to reduce file size while maintaining good quality for analysis."
      ],
      "metadata": {
        "id": "sample_rate_explanation"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Visualize the Waveform\n",
        "\n",
        "A **waveform** shows amplitude (loudness) over time. It's the most basic visualization of audio and resembles what you might see in audio editing software.\n",
        "\n",
        "**What to look for:**\n",
        "- **Peaks**: Loud moments in the music\n",
        "- **Quiet sections**: Near-zero amplitude areas indicate silence or soft passages\n",
        "- **Attack and decay**: The shape of individual notes reveals articulation style"
      ],
      "metadata": {
        "id": "waveform"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a figure with a specific size\n",
        "plt.figure(figsize=(14, 4))\n",
        "\n",
        "# Plot the waveform using librosa's display function\n",
        "librosa.display.waveshow(y, sr=sr, alpha=0.8)\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Time (seconds)')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.title('Audio Waveform - Trumpet')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "waveform_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Create a Spectrogram\n",
        "\n",
        "A **spectrogram** shows frequency content over time. It reveals which pitches are present at each moment—information invisible in a simple waveform.\n",
        "\n",
        "- **X-axis**: Time\n",
        "- **Y-axis**: Frequency (pitch)\n",
        "- **Color**: Intensity (loudness)\n",
        "\n",
        "**Reading a spectrogram:**\n",
        "- Horizontal lines = Sustained pitches or harmonics\n",
        "- Bright spots = Loud frequency components\n",
        "- Vertical stripes = Transients (attacks, percussive sounds)\n",
        "- Multiple horizontal lines at regular intervals = Harmonic series of a pitched instrument"
      ],
      "metadata": {
        "id": "spectrogram"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the Short-Time Fourier Transform (STFT)\n",
        "D = librosa.stft(y)\n",
        "\n",
        "# Convert amplitude to decibels for better visualization\n",
        "S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
        "\n",
        "# Create the spectrogram plot\n",
        "plt.figure(figsize=(14, 6))\n",
        "librosa.display.specshow(S_db, sr=sr, x_axis='time', y_axis='hz', cmap='magma')\n",
        "plt.colorbar(format='%+2.0f dB')\n",
        "plt.xlabel('Time (seconds)')\n",
        "plt.ylabel('Frequency (Hz)')\n",
        "plt.title('Spectrogram - Trumpet')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "spectrogram_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Create a Mel Spectrogram\n",
        "\n",
        "A **Mel spectrogram** uses a frequency scale that better matches human hearing perception. We hear the difference between 100 Hz and 200 Hz more easily than between 5000 Hz and 5100 Hz, even though both are 100 Hz apart. The Mel scale accounts for this.\n",
        "\n",
        "**Why use Mel spectrograms?**\n",
        "- Better match to human perception of pitch\n",
        "- Commonly used in machine learning for music classification\n",
        "- Reduces data while keeping perceptually relevant information"
      ],
      "metadata": {
        "id": "mel_spectrogram"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the Mel spectrogram\n",
        "S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
        "\n",
        "# Convert to decibels\n",
        "S_db = librosa.power_to_db(S, ref=np.max)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(14, 6))\n",
        "librosa.display.specshow(S_db, sr=sr, x_axis='time', y_axis='mel', cmap='viridis')\n",
        "plt.colorbar(format='%+2.0f dB')\n",
        "plt.xlabel('Time (seconds)')\n",
        "plt.ylabel('Frequency (Mel scale)')\n",
        "plt.title('Mel Spectrogram - Trumpet')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mel_spectrogram_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Upload Your Own Audio\n",
        "\n",
        "You can upload your own audio file and analyze it! Run the cell below to open a file picker."
      ],
      "metadata": {
        "id": "upload_own"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload a file from your computer\n",
        "from google.colab import files\n",
        "\n",
        "# This will open a file picker dialog\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the filename (assuming one file uploaded)\n",
        "if uploaded:\n",
        "    filename = list(uploaded.keys())[0]\n",
        "\n",
        "    # Load the uploaded audio\n",
        "    y_custom, sr_custom = librosa.load(filename)\n",
        "\n",
        "    # Print info and play\n",
        "    print(f\"\\nLoaded: {filename}\")\n",
        "    print(f\"Sample rate: {sr_custom} Hz\")\n",
        "    print(f\"Duration: {len(y_custom) / sr_custom:.2f} seconds\")\n",
        "    Audio(y_custom, rate=sr_custom)"
      ],
      "metadata": {
        "id": "upload_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Complete Visualization Suite\n",
        "\n",
        "Here's a complete script that creates all three visualizations side by side. You can modify the audio source variable to switch between the example audio and your uploaded file."
      ],
      "metadata": {
        "id": "complete_example"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose which audio to analyze (change to y_custom, sr_custom to use your uploaded file)\n",
        "audio_data = y\n",
        "sample_rate = sr\n",
        "\n",
        "# Create a figure with 3 subplots\n",
        "fig, axes = plt.subplots(3, 1, figsize=(14, 12))\n",
        "\n",
        "# 1. Waveform\n",
        "librosa.display.waveshow(audio_data, sr=sample_rate, ax=axes[0], alpha=0.8)\n",
        "axes[0].set_title('Waveform')\n",
        "axes[0].set_xlabel('Time (seconds)')\n",
        "axes[0].set_ylabel('Amplitude')\n",
        "\n",
        "# 2. Spectrogram\n",
        "D = librosa.stft(audio_data)\n",
        "S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
        "img1 = librosa.display.specshow(S_db, sr=sample_rate, x_axis='time', y_axis='hz', ax=axes[1], cmap='magma')\n",
        "axes[1].set_title('Spectrogram')\n",
        "fig.colorbar(img1, ax=axes[1], format='%+2.0f dB')\n",
        "\n",
        "# 3. Mel Spectrogram\n",
        "S_mel = librosa.feature.melspectrogram(y=audio_data, sr=sample_rate, n_mels=128)\n",
        "S_mel_db = librosa.power_to_db(S_mel, ref=np.max)\n",
        "img2 = librosa.display.specshow(S_mel_db, sr=sample_rate, x_axis='time', y_axis='mel', ax=axes[2], cmap='viridis')\n",
        "axes[2].set_title('Mel Spectrogram')\n",
        "fig.colorbar(img2, ax=axes[2], format='%+2.0f dB')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Play the audio\n",
        "Audio(audio_data, rate=sample_rate)"
      ],
      "metadata": {
        "id": "complete_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Practice Exercises\n",
        "\n",
        "Try these exercises to solidify your understanding:\n",
        "\n",
        "1. **Load a different example**: Try `librosa.ex('nutcracker')` or `librosa.ex('choice')` instead of 'trumpet'\n",
        "2. **Change the color map**: Replace 'magma' or 'viridis' with 'plasma', 'inferno', or 'coolwarm'\n",
        "3. **Adjust the Mel bins**: Change `n_mels=128` to `n_mels=64` or `n_mels=256` and observe the difference\n",
        "4. **Compare instruments**: Upload recordings of different instruments and compare their spectrograms"
      ],
      "metadata": {
        "id": "exercises"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your practice space - try the exercises here!\n",
        "\n",
        "# Exercise 1: Load a different example\n",
        "# y2, sr2 = librosa.load(librosa.ex('nutcracker'))\n",
        "\n",
        "# Exercise 2 & 3: Experiment with visualization settings\n",
        "# Add your code here!"
      ],
      "metadata": {
        "id": "practice"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Key Concepts Summary\n",
        "\n",
        "1. **Audio as data**: Audio is represented as numerical arrays (samples)\n",
        "2. **Sample rate**: Determines audio resolution and quality (samples per second)\n",
        "3. **Waveform**: Shows amplitude over time—the raw shape of sound\n",
        "4. **Spectrogram**: Reveals frequency content over time via the Short-Time Fourier Transform\n",
        "5. **Mel spectrogram**: Aligns with human pitch perception for more meaningful analysis\n",
        "\n",
        "---\n",
        "\n",
        "**Next tutorial**: Learn about beat detection and tempo analysis with librosa!"
      ],
      "metadata": {
        "id": "summary"
      }
    }
  ]
}
