{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial: Audio Effects & Exporting with librosa and soundfile\n",
        "\n",
        "This tutorial teaches you how to apply audio effects using librosa and export your processed audio using soundfile. These skills let you manipulate audio programmaticallyâ€”from changing tempo to creating special effects.\n",
        "\n",
        "**What you'll learn:**\n",
        "- How to time-stretch audio (change speed without changing pitch)\n",
        "- How to pitch-shift audio (transpose without changing speed)\n",
        "- How to normalize and apply fades\n",
        "- How to export audio in various formats"
      ],
      "metadata": {
        "id": "intro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Setup\n",
        "\n",
        "Install and import the required libraries."
      ],
      "metadata": {
        "id": "setup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install libraries\n",
        "!pip install librosa soundfile\n",
        "\n",
        "# Import libraries\n",
        "import librosa\n",
        "import librosa.display\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Audio\n",
        "import os\n",
        "\n",
        "print(\"Libraries loaded successfully!\")\n",
        "print(f\"soundfile version: {sf.__version__}\")"
      ],
      "metadata": {
        "id": "setup_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Load Audio\n",
        "\n",
        "Load an audio file and examine its properties."
      ],
      "metadata": {
        "id": "load"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load audio\n",
        "y, sr = librosa.load(librosa.ex('trumpet'))\n",
        "\n",
        "print(f\"Sample rate: {sr} Hz\")\n",
        "print(f\"Duration: {len(y) / sr:.2f} seconds\")\n",
        "print(f\"Number of samples: {len(y)}\")\n",
        "print(f\"Data type: {y.dtype}\")\n",
        "\n",
        "# Listen to the original\n",
        "print(\"\\nOriginal audio:\")\n",
        "Audio(y, rate=sr)"
      ],
      "metadata": {
        "id": "load_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Time Stretching\n",
        "\n",
        "**Time stretching** changes duration without altering pitch. Perfect for practice!\n",
        "\n",
        "- `rate > 1.0`: Audio plays faster\n",
        "- `rate < 1.0`: Audio plays slower"
      ],
      "metadata": {
        "id": "time_stretch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Slow down to 75% speed (great for practicing difficult passages!)\n",
        "y_slow = librosa.effects.time_stretch(y, rate=0.75)\n",
        "\n",
        "print(f\"Original duration: {len(y) / sr:.2f} seconds\")\n",
        "print(f\"Slowed duration: {len(y_slow) / sr:.2f} seconds\")\n",
        "\n",
        "print(\"\\nSlowed to 75% speed:\")\n",
        "Audio(y_slow, rate=sr)"
      ],
      "metadata": {
        "id": "time_stretch_slow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Speed up to 125% speed\n",
        "y_fast = librosa.effects.time_stretch(y, rate=1.25)\n",
        "\n",
        "print(f\"Original duration: {len(y) / sr:.2f} seconds\")\n",
        "print(f\"Fast duration: {len(y_fast) / sr:.2f} seconds\")\n",
        "\n",
        "print(\"\\nSped up to 125% speed:\")\n",
        "Audio(y_fast, rate=sr)"
      ],
      "metadata": {
        "id": "time_stretch_fast"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Pitch Shifting\n",
        "\n",
        "**Pitch shifting** transposes audio without changing tempo.\n",
        "\n",
        "- `n_steps` = number of semitones to shift\n",
        "- Positive = higher pitch\n",
        "- Negative = lower pitch\n",
        "- 12 semitones = 1 octave"
      ],
      "metadata": {
        "id": "pitch_shift"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shift up by 4 semitones (a major third)\n",
        "y_up = librosa.effects.pitch_shift(y, sr=sr, n_steps=4)\n",
        "\n",
        "print(\"Pitch shifted UP by 4 semitones (major third):\")\n",
        "Audio(y_up, rate=sr)"
      ],
      "metadata": {
        "id": "pitch_shift_up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shift down by 5 semitones (a perfect fourth)\n",
        "y_down = librosa.effects.pitch_shift(y, sr=sr, n_steps=-5)\n",
        "\n",
        "print(\"Pitch shifted DOWN by 5 semitones (perfect fourth):\")\n",
        "Audio(y_down, rate=sr)"
      ],
      "metadata": {
        "id": "pitch_shift_down"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shift down by 12 semitones (one octave)\n",
        "y_octave_down = librosa.effects.pitch_shift(y, sr=sr, n_steps=-12)\n",
        "\n",
        "print(\"Pitch shifted DOWN by 12 semitones (one octave):\")\n",
        "Audio(y_octave_down, rate=sr)"
      ],
      "metadata": {
        "id": "pitch_shift_octave"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Combining Effects\n",
        "\n",
        "Chain multiple effects together for complex transformations."
      ],
      "metadata": {
        "id": "combine"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Slow down to 70% AND transpose down 2 semitones\n",
        "# (useful for practicing a difficult passage in a lower key)\n",
        "y_practice = librosa.effects.time_stretch(y, rate=0.7)\n",
        "y_practice = librosa.effects.pitch_shift(y_practice, sr=sr, n_steps=-2)\n",
        "\n",
        "print(f\"Original duration: {len(y) / sr:.2f} seconds\")\n",
        "print(f\"Practice version: {len(y_practice) / sr:.2f} seconds\")\n",
        "print(\"\\nSlowed to 70% and transposed down 2 semitones:\")\n",
        "Audio(y_practice, rate=sr)"
      ],
      "metadata": {
        "id": "combine_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Volume Normalization\n",
        "\n",
        "**Normalization** adjusts volume so the loudest peak reaches a target level."
      ],
      "metadata": {
        "id": "normalize"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the current peak amplitude\n",
        "print(f\"Original peak amplitude: {np.max(np.abs(y)):.4f}\")\n",
        "\n",
        "# Normalize to peak at 1.0 (maximum without clipping)\n",
        "y_normalized = librosa.util.normalize(y)\n",
        "print(f\"Normalized peak amplitude: {np.max(np.abs(y_normalized)):.4f}\")\n",
        "\n",
        "# Normalize to -3 dB below max\n",
        "target_amplitude = 10**(-3/20)  # Convert dB to linear\n",
        "y_normalized_3db = librosa.util.normalize(y) * target_amplitude\n",
        "print(f\"Normalized to -3dB: {np.max(np.abs(y_normalized_3db)):.4f}\")\n",
        "\n",
        "Audio(y_normalized, rate=sr)"
      ],
      "metadata": {
        "id": "normalize_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Export Audio with soundfile\n",
        "\n",
        "**soundfile** saves processed audio to various formats:\n",
        "- WAV: Uncompressed, lossless\n",
        "- FLAC: Compressed, lossless\n",
        "- OGG: Compressed, lossy but small"
      ],
      "metadata": {
        "id": "export"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Export as WAV (uncompressed, lossless)\n",
        "sf.write('output_processed.wav', y_slow, sr)\n",
        "print(\"Saved: output_processed.wav\")\n",
        "\n",
        "# Export as FLAC (compressed, lossless)\n",
        "sf.write('output_processed.flac', y_slow, sr)\n",
        "print(\"Saved: output_processed.flac\")\n",
        "\n",
        "# Check file sizes\n",
        "wav_size = os.path.getsize('output_processed.wav')\n",
        "flac_size = os.path.getsize('output_processed.flac')\n",
        "print(f\"\\nWAV file size: {wav_size:,} bytes\")\n",
        "print(f\"FLAC file size: {flac_size:,} bytes\")\n",
        "print(f\"FLAC is {100 * (1 - flac_size/wav_size):.1f}% smaller\")"
      ],
      "metadata": {
        "id": "export_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 8: Batch Processing\n",
        "\n",
        "Create multiple practice versions at different tempos and transpositions."
      ],
      "metadata": {
        "id": "batch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define practice variations\n",
        "variations = [\n",
        "    {'name': 'slow_50', 'rate': 0.5, 'semitones': 0},\n",
        "    {'name': 'slow_75', 'rate': 0.75, 'semitones': 0},\n",
        "    {'name': 'normal_down_2', 'rate': 1.0, 'semitones': -2},\n",
        "    {'name': 'slow_75_down_3', 'rate': 0.75, 'semitones': -3},\n",
        "]\n",
        "\n",
        "# Process and save each variation\n",
        "for var in variations:\n",
        "    # Apply effects\n",
        "    y_processed = librosa.effects.time_stretch(y, rate=var['rate'])\n",
        "    if var['semitones'] != 0:\n",
        "        y_processed = librosa.effects.pitch_shift(y_processed, sr=sr, n_steps=var['semitones'])\n",
        "    \n",
        "    # Normalize\n",
        "    y_processed = librosa.util.normalize(y_processed)\n",
        "    \n",
        "    # Save\n",
        "    filename = f\"practice_{var['name']}.wav\"\n",
        "    sf.write(filename, y_processed, sr)\n",
        "    print(f\"Created: {filename} (rate={var['rate']}, semitones={var['semitones']}\")\n",
        "\n",
        "print(\"\\nAll practice files created!\")"
      ],
      "metadata": {
        "id": "batch_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 9: Read Audio Metadata\n",
        "\n",
        "soundfile can read file information without loading the audio data."
      ],
      "metadata": {
        "id": "metadata"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read file info\n",
        "info = sf.info('output_processed.wav')\n",
        "\n",
        "print(\"=== Audio File Information ===\")\n",
        "print(f\"Duration: {info.duration:.2f} seconds\")\n",
        "print(f\"Sample rate: {info.samplerate} Hz\")\n",
        "print(f\"Channels: {info.channels}\")\n",
        "print(f\"Format: {info.format}\")\n",
        "print(f\"Subtype: {info.subtype}\")\n",
        "print(f\"Frames (samples): {info.frames}\")"
      ],
      "metadata": {
        "id": "metadata_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 10: Create Custom Fade Effects\n",
        "\n",
        "Build fade-in and fade-out effects by manipulating the audio directly."
      ],
      "metadata": {
        "id": "fades"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define fade functions\n",
        "def apply_fade_in(audio, sr, duration=1.0):\n",
        "    \"\"\"Apply a fade-in effect to the beginning of audio.\"\"\"\n",
        "    fade_samples = int(duration * sr)\n",
        "    fade_samples = min(fade_samples, len(audio))\n",
        "    \n",
        "    fade_curve = np.linspace(0, 1, fade_samples)\n",
        "    \n",
        "    audio_faded = audio.copy()\n",
        "    audio_faded[:fade_samples] = audio_faded[:fade_samples] * fade_curve\n",
        "    \n",
        "    return audio_faded\n",
        "\n",
        "def apply_fade_out(audio, sr, duration=1.0):\n",
        "    \"\"\"Apply a fade-out effect to the end of audio.\"\"\"\n",
        "    fade_samples = int(duration * sr)\n",
        "    fade_samples = min(fade_samples, len(audio))\n",
        "    \n",
        "    fade_curve = np.linspace(1, 0, fade_samples)\n",
        "    \n",
        "    audio_faded = audio.copy()\n",
        "    audio_faded[-fade_samples:] = audio_faded[-fade_samples:] * fade_curve\n",
        "    \n",
        "    return audio_faded\n",
        "\n",
        "# Apply both fades\n",
        "y_faded = apply_fade_in(y, sr, duration=0.5)\n",
        "y_faded = apply_fade_out(y_faded, sr, duration=0.5)\n",
        "\n",
        "# Save\n",
        "sf.write('output_with_fades.wav', y_faded, sr)\n",
        "print(\"Created audio with fade-in and fade-out\")\n",
        "\n",
        "# Listen\n",
        "Audio(y_faded, rate=sr)"
      ],
      "metadata": {
        "id": "fades_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 11: Visualize Before and After\n",
        "\n",
        "Compare original and processed audio visually."
      ],
      "metadata": {
        "id": "visualize"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create comparison plot\n",
        "fig, axes = plt.subplots(3, 1, figsize=(14, 10))\n",
        "\n",
        "# Original\n",
        "librosa.display.waveshow(y, sr=sr, ax=axes[0], alpha=0.7)\n",
        "axes[0].set_title('Original Audio')\n",
        "\n",
        "# Time stretched (slow)\n",
        "librosa.display.waveshow(y_slow, sr=sr, ax=axes[1], alpha=0.7, color='green')\n",
        "axes[1].set_title('Time Stretched (75% speed)')\n",
        "\n",
        "# With fades\n",
        "librosa.display.waveshow(y_faded, sr=sr, ax=axes[2], alpha=0.7, color='purple')\n",
        "axes[2].set_title('With Fade In/Out Effects')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "visualize_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 12: Complete Processing Function\n",
        "\n",
        "A reusable function for processing and exporting audio."
      ],
      "metadata": {
        "id": "complete"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_and_export(y, sr, output_path, \n",
        "                       speed_factor=1.0, \n",
        "                       pitch_semitones=0, \n",
        "                       normalize=True,\n",
        "                       fade_in=0, \n",
        "                       fade_out=0,\n",
        "                       output_format='wav'):\n",
        "    \"\"\"\n",
        "    Complete audio processing and export function.\n",
        "    \n",
        "    Args:\n",
        "        y: Audio data\n",
        "        sr: Sample rate\n",
        "        output_path: Path for output file (without extension)\n",
        "        speed_factor: Time stretch factor (1.0 = no change)\n",
        "        pitch_semitones: Pitch shift in semitones (0 = no change)\n",
        "        normalize: Whether to normalize volume\n",
        "        fade_in: Fade-in duration in seconds\n",
        "        fade_out: Fade-out duration in seconds\n",
        "        output_format: Output format ('wav', 'flac')\n",
        "    \"\"\"\n",
        "    y_out = y.copy()\n",
        "    \n",
        "    # Apply time stretching\n",
        "    if speed_factor != 1.0:\n",
        "        y_out = librosa.effects.time_stretch(y_out, rate=speed_factor)\n",
        "    \n",
        "    # Apply pitch shifting\n",
        "    if pitch_semitones != 0:\n",
        "        y_out = librosa.effects.pitch_shift(y_out, sr=sr, n_steps=pitch_semitones)\n",
        "    \n",
        "    # Apply fades\n",
        "    if fade_in > 0:\n",
        "        y_out = apply_fade_in(y_out, sr, fade_in)\n",
        "    if fade_out > 0:\n",
        "        y_out = apply_fade_out(y_out, sr, fade_out)\n",
        "    \n",
        "    # Normalize\n",
        "    if normalize:\n",
        "        y_out = librosa.util.normalize(y_out)\n",
        "    \n",
        "    # Export\n",
        "    output_file = f\"{output_path}.{output_format}\"\n",
        "    sf.write(output_file, y_out, sr)\n",
        "    \n",
        "    return output_file, len(y_out) / sr\n",
        "\n",
        "# Example usage\n",
        "output_file, duration = process_and_export(\n",
        "    y, sr,\n",
        "    output_path=\"my_processed_audio\",\n",
        "    speed_factor=0.8,\n",
        "    pitch_semitones=-2,\n",
        "    normalize=True,\n",
        "    fade_in=0.3,\n",
        "    fade_out=0.5,\n",
        "    output_format='wav'\n",
        ")\n",
        "\n",
        "print(f\"Created: {output_file}\")\n",
        "print(f\"Duration: {duration:.2f} seconds\")\n",
        "\n",
        "# Listen to the result\n",
        "y_result, sr_result = librosa.load(output_file)\n",
        "Audio(y_result, rate=sr_result)"
      ],
      "metadata": {
        "id": "complete_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 13: Upload and Process Your Own Audio\n",
        "\n",
        "Try processing your own audio file!"
      ],
      "metadata": {
        "id": "upload"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload your own file\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "if uploaded:\n",
        "    filename = list(uploaded.keys())[0]\n",
        "    y_custom, sr_custom = librosa.load(filename)\n",
        "    \n",
        "    print(f\"\\nLoaded: {filename}\")\n",
        "    print(f\"Duration: {len(y_custom) / sr_custom:.2f} seconds\")\n",
        "    \n",
        "    # Create a practice version\n",
        "    output_file, duration = process_and_export(\n",
        "        y_custom, sr_custom,\n",
        "        output_path=\"my_practice_version\",\n",
        "        speed_factor=0.75,  # Slow to 75%\n",
        "        pitch_semitones=0,\n",
        "        normalize=True,\n",
        "        fade_in=0.5,\n",
        "        fade_out=0.5\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nCreated practice version: {output_file}\")\n",
        "    print(f\"New duration: {duration:.2f} seconds\")\n",
        "    \n",
        "    # Download the processed file\n",
        "    files.download(output_file)\n",
        "    \n",
        "    # Listen\n",
        "    y_result, sr_result = librosa.load(output_file)\n",
        "    Audio(y_result, rate=sr_result)"
      ],
      "metadata": {
        "id": "upload_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Practice Exercises\n",
        "\n",
        "1. **Create a practice tool**: Make versions at 50%, 75%, and 100% speed\n",
        "2. **Transposition helper**: Generate all 12 transpositions of a melody\n",
        "3. **Crossfade**: Blend two audio files together"
      ],
      "metadata": {
        "id": "exercises"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Practice space - try the exercises here!\n",
        "\n",
        "# Exercise 2: Generate all 12 transpositions\n",
        "# for semitones in range(-6, 6):\n",
        "#     y_transposed = librosa.effects.pitch_shift(y, sr=sr, n_steps=semitones)\n",
        "#     sf.write(f'transposed_{semitones:+d}.wav', y_transposed, sr)"
      ],
      "metadata": {
        "id": "practice"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Key Concepts Summary\n",
        "\n",
        "1. **Time stretching** changes duration without affecting pitch\n",
        "2. **Pitch shifting** transposes without affecting tempo\n",
        "3. **soundfile** provides robust audio file I/O\n",
        "4. **Effects can be chained** for complex processing\n",
        "5. **Normalization** ensures consistent volume levels\n",
        "\n",
        "---\n",
        "\n",
        "**Congratulations!** You've completed the librosa and soundfile tutorial series. You now have the tools to analyze, process, and export audio programmatically!"
      ],
      "metadata": {
        "id": "summary"
      }
    }
  ]
}
